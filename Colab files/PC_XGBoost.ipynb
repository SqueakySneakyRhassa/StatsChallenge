{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ppTcVKhPG9K"
      },
      "source": [
        "## Practitioners' Challenge\n",
        "### Extreme Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snsZnoEzO6hJ"
      },
      "outputs": [],
      "source": [
        "# loading packages\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import (StandardScaler, PolynomialFeatures)\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    explained_variance_score\n",
        ")\n",
        "from sklearn.model_selection import (RandomizedSearchCV, GridSearchCV)\n",
        "from sklearn.pipeline import Pipeline\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import losses\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K7PgDl2XGbN"
      },
      "outputs": [],
      "source": [
        "# loading functions\n",
        "import Functions as Func\n",
        "\n",
        "# loading the dataset\n",
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f7WB2naZu1V"
      },
      "outputs": [],
      "source": [
        "# defining variables\n",
        "df, X = Func.process_insurance_data()\n",
        "\n",
        "# creating train and test sets\n",
        "df_train, df_test, X_train, X_test = train_test_split(df, X, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2uDrxUGbFMm"
      },
      "outputs": [],
      "source": [
        "# creating regression matrices\n",
        "dtrain_reg = xgb.DMatrix(X_train, label=df_train[\"Frequency\"], weight=df_train[\"Exposure\"])\n",
        "dtest_reg = xgb.DMatrix(X_test, label=df_test[\"Frequency\"], weight=df_test[\"Exposure\"])\n",
        "\n",
        "# defining hyperparameters\n",
        "params = {\"objective\": \"count:poisson\", \"tree_method\": \"hist\"}\n",
        "evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7U8j1PxftLy",
        "outputId": "1a3d6229-5822-46c7-8f3b-98625ecf13d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-poisson-nloglik:0.62412\tvalidation-poisson-nloglik:0.62346\n",
            "[1]\ttrain-poisson-nloglik:0.56599\tvalidation-poisson-nloglik:0.56535\n",
            "[2]\ttrain-poisson-nloglik:0.51683\tvalidation-poisson-nloglik:0.51621\n",
            "[3]\ttrain-poisson-nloglik:0.47550\tvalidation-poisson-nloglik:0.47490\n",
            "[4]\ttrain-poisson-nloglik:0.44072\tvalidation-poisson-nloglik:0.44014\n",
            "[5]\ttrain-poisson-nloglik:0.41168\tvalidation-poisson-nloglik:0.41115\n",
            "[6]\ttrain-poisson-nloglik:0.38735\tvalidation-poisson-nloglik:0.38685\n",
            "[7]\ttrain-poisson-nloglik:0.36717\tvalidation-poisson-nloglik:0.36671\n",
            "[8]\ttrain-poisson-nloglik:0.35038\tvalidation-poisson-nloglik:0.34996\n",
            "[9]\ttrain-poisson-nloglik:0.33657\tvalidation-poisson-nloglik:0.33619\n",
            "[10]\ttrain-poisson-nloglik:0.32523\tvalidation-poisson-nloglik:0.32490\n",
            "[11]\ttrain-poisson-nloglik:0.31588\tvalidation-poisson-nloglik:0.31560\n",
            "[12]\ttrain-poisson-nloglik:0.30830\tvalidation-poisson-nloglik:0.30808\n",
            "[13]\ttrain-poisson-nloglik:0.30214\tvalidation-poisson-nloglik:0.30202\n",
            "[14]\ttrain-poisson-nloglik:0.29711\tvalidation-poisson-nloglik:0.29707\n",
            "[15]\ttrain-poisson-nloglik:0.29313\tvalidation-poisson-nloglik:0.29320\n",
            "[16]\ttrain-poisson-nloglik:0.28985\tvalidation-poisson-nloglik:0.29000\n",
            "[17]\ttrain-poisson-nloglik:0.28728\tvalidation-poisson-nloglik:0.28753\n",
            "[18]\ttrain-poisson-nloglik:0.28520\tvalidation-poisson-nloglik:0.28559\n",
            "[19]\ttrain-poisson-nloglik:0.28348\tvalidation-poisson-nloglik:0.28400\n",
            "[20]\ttrain-poisson-nloglik:0.28201\tvalidation-poisson-nloglik:0.28265\n",
            "[21]\ttrain-poisson-nloglik:0.28094\tvalidation-poisson-nloglik:0.28174\n",
            "[22]\ttrain-poisson-nloglik:0.28000\tvalidation-poisson-nloglik:0.28090\n",
            "[23]\ttrain-poisson-nloglik:0.27928\tvalidation-poisson-nloglik:0.28029\n",
            "[24]\ttrain-poisson-nloglik:0.27860\tvalidation-poisson-nloglik:0.27972\n",
            "[25]\ttrain-poisson-nloglik:0.27811\tvalidation-poisson-nloglik:0.27937\n",
            "[26]\ttrain-poisson-nloglik:0.27765\tvalidation-poisson-nloglik:0.27903\n",
            "[27]\ttrain-poisson-nloglik:0.27730\tvalidation-poisson-nloglik:0.27877\n",
            "[28]\ttrain-poisson-nloglik:0.27697\tvalidation-poisson-nloglik:0.27859\n",
            "[29]\ttrain-poisson-nloglik:0.27669\tvalidation-poisson-nloglik:0.27845\n",
            "[30]\ttrain-poisson-nloglik:0.27644\tvalidation-poisson-nloglik:0.27833\n",
            "[31]\ttrain-poisson-nloglik:0.27623\tvalidation-poisson-nloglik:0.27826\n",
            "[32]\ttrain-poisson-nloglik:0.27599\tvalidation-poisson-nloglik:0.27816\n",
            "[33]\ttrain-poisson-nloglik:0.27581\tvalidation-poisson-nloglik:0.27809\n",
            "[34]\ttrain-poisson-nloglik:0.27566\tvalidation-poisson-nloglik:0.27808\n",
            "[35]\ttrain-poisson-nloglik:0.27549\tvalidation-poisson-nloglik:0.27803\n",
            "[36]\ttrain-poisson-nloglik:0.27532\tvalidation-poisson-nloglik:0.27800\n",
            "[37]\ttrain-poisson-nloglik:0.27519\tvalidation-poisson-nloglik:0.27797\n",
            "[38]\ttrain-poisson-nloglik:0.27504\tvalidation-poisson-nloglik:0.27793\n",
            "[39]\ttrain-poisson-nloglik:0.27488\tvalidation-poisson-nloglik:0.27795\n",
            "[40]\ttrain-poisson-nloglik:0.27474\tvalidation-poisson-nloglik:0.27795\n",
            "[41]\ttrain-poisson-nloglik:0.27463\tvalidation-poisson-nloglik:0.27796\n",
            "[42]\ttrain-poisson-nloglik:0.27450\tvalidation-poisson-nloglik:0.27794\n",
            "[43]\ttrain-poisson-nloglik:0.27439\tvalidation-poisson-nloglik:0.27792\n",
            "[44]\ttrain-poisson-nloglik:0.27427\tvalidation-poisson-nloglik:0.27791\n",
            "[45]\ttrain-poisson-nloglik:0.27418\tvalidation-poisson-nloglik:0.27791\n",
            "[46]\ttrain-poisson-nloglik:0.27406\tvalidation-poisson-nloglik:0.27789\n",
            "[47]\ttrain-poisson-nloglik:0.27394\tvalidation-poisson-nloglik:0.27787\n",
            "[48]\ttrain-poisson-nloglik:0.27383\tvalidation-poisson-nloglik:0.27790\n",
            "[49]\ttrain-poisson-nloglik:0.27370\tvalidation-poisson-nloglik:0.27791\n",
            "[50]\ttrain-poisson-nloglik:0.27362\tvalidation-poisson-nloglik:0.27791\n",
            "[51]\ttrain-poisson-nloglik:0.27348\tvalidation-poisson-nloglik:0.27789\n",
            "[52]\ttrain-poisson-nloglik:0.27336\tvalidation-poisson-nloglik:0.27789\n",
            "[53]\ttrain-poisson-nloglik:0.27328\tvalidation-poisson-nloglik:0.27788\n",
            "[54]\ttrain-poisson-nloglik:0.27321\tvalidation-poisson-nloglik:0.27788\n",
            "[55]\ttrain-poisson-nloglik:0.27311\tvalidation-poisson-nloglik:0.27789\n",
            "[56]\ttrain-poisson-nloglik:0.27297\tvalidation-poisson-nloglik:0.27787\n",
            "[57]\ttrain-poisson-nloglik:0.27284\tvalidation-poisson-nloglik:0.27786\n",
            "[58]\ttrain-poisson-nloglik:0.27279\tvalidation-poisson-nloglik:0.27788\n",
            "[59]\ttrain-poisson-nloglik:0.27267\tvalidation-poisson-nloglik:0.27789\n",
            "[60]\ttrain-poisson-nloglik:0.27257\tvalidation-poisson-nloglik:0.27793\n",
            "[61]\ttrain-poisson-nloglik:0.27249\tvalidation-poisson-nloglik:0.27792\n",
            "[62]\ttrain-poisson-nloglik:0.27243\tvalidation-poisson-nloglik:0.27795\n",
            "[63]\ttrain-poisson-nloglik:0.27231\tvalidation-poisson-nloglik:0.27795\n",
            "[64]\ttrain-poisson-nloglik:0.27218\tvalidation-poisson-nloglik:0.27796\n",
            "[65]\ttrain-poisson-nloglik:0.27209\tvalidation-poisson-nloglik:0.27798\n",
            "[66]\ttrain-poisson-nloglik:0.27202\tvalidation-poisson-nloglik:0.27800\n",
            "[67]\ttrain-poisson-nloglik:0.27196\tvalidation-poisson-nloglik:0.27801\n"
          ]
        }
      ],
      "source": [
        "# training the model\n",
        "n = 1000\n",
        "xgb_freq = xgb.train(\n",
        "   params=params,\n",
        "   dtrain=dtrain_reg,\n",
        "   num_boost_round=n,\n",
        "   evals=evals,\n",
        "   early_stopping_rounds=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGzB_Rc4Rodi",
        "outputId": "c1a12722-1381-41c7-e4a3-85f85525c0a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    train-mae-mean  train-mae-std  train-rmse-mean  train-rmse-std  \\\n",
            "0         0.573481       0.000235         0.689590        0.001739   \n",
            "1         0.512560       0.000256         0.644368        0.001856   \n",
            "2         0.460069       0.000271         0.608672        0.001953   \n",
            "3         0.414879       0.000289         0.580823        0.002053   \n",
            "4         0.375944       0.000305         0.559283        0.002127   \n",
            "5         0.342402       0.000319         0.542752        0.002203   \n",
            "6         0.313500       0.000344         0.530164        0.002258   \n",
            "7         0.288644       0.000368         0.520660        0.002308   \n",
            "8         0.267241       0.000382         0.513512        0.002336   \n",
            "9         0.248815       0.000358         0.508137        0.002358   \n",
            "10        0.232953       0.000367         0.504125        0.002378   \n",
            "11        0.219295       0.000380         0.501118        0.002400   \n",
            "12        0.207579       0.000389         0.498901        0.002406   \n",
            "13        0.197468       0.000373         0.497223        0.002408   \n",
            "14        0.188783       0.000391         0.495973        0.002421   \n",
            "15        0.181311       0.000382         0.495036        0.002433   \n",
            "16        0.174896       0.000391         0.494338        0.002440   \n",
            "17        0.169378       0.000395         0.493805        0.002438   \n",
            "18        0.164639       0.000397         0.493396        0.002436   \n",
            "19        0.160577       0.000381         0.493089        0.002437   \n",
            "20        0.157081       0.000363         0.492844        0.002442   \n",
            "21        0.154085       0.000378         0.492658        0.002448   \n",
            "22        0.151498       0.000384         0.492487        0.002450   \n",
            "23        0.149307       0.000388         0.492380        0.002449   \n",
            "24        0.147402       0.000406         0.492271        0.002458   \n",
            "25        0.145781       0.000391         0.492190        0.002458   \n",
            "26        0.144363       0.000395         0.492100        0.002457   \n",
            "27        0.143160       0.000399         0.492033        0.002447   \n",
            "28        0.142121       0.000410         0.491972        0.002453   \n",
            "29        0.141234       0.000419         0.491913        0.002449   \n",
            "30        0.140471       0.000413         0.491856        0.002444   \n",
            "31        0.139811       0.000418         0.491804        0.002445   \n",
            "32        0.139246       0.000402         0.491751        0.002451   \n",
            "33        0.138755       0.000399         0.491697        0.002452   \n",
            "34        0.138329       0.000402         0.491648        0.002458   \n",
            "35        0.137967       0.000405         0.491603        0.002456   \n",
            "36        0.137654       0.000410         0.491564        0.002459   \n",
            "37        0.137383       0.000410         0.491519        0.002462   \n",
            "38        0.137142       0.000403         0.491476        0.002469   \n",
            "39        0.136936       0.000408         0.491433        0.002472   \n",
            "40        0.136749       0.000417         0.491397        0.002474   \n",
            "41        0.136581       0.000426         0.491345        0.002483   \n",
            "42        0.136435       0.000428         0.491303        0.002484   \n",
            "43        0.136309       0.000433         0.491271        0.002486   \n",
            "\n",
            "    test-mae-mean  test-mae-std  test-rmse-mean  test-rmse-std  \n",
            "0        0.573519      0.000623        0.689605       0.007043  \n",
            "1        0.512635      0.000640        0.644432       0.007555  \n",
            "2        0.460170      0.000660        0.608776       0.008016  \n",
            "3        0.415004      0.000660        0.580966       0.008393  \n",
            "4        0.376088      0.000676        0.559461       0.008732  \n",
            "5        0.342567      0.000669        0.542970       0.008991  \n",
            "6        0.313680      0.000662        0.530405       0.009208  \n",
            "7        0.288841      0.000656        0.520940       0.009372  \n",
            "8        0.267450      0.000662        0.513819       0.009511  \n",
            "9        0.249038      0.000695        0.508478       0.009613  \n",
            "10       0.233193      0.000698        0.504496       0.009691  \n",
            "11       0.219549      0.000698        0.501518       0.009742  \n",
            "12       0.207847      0.000699        0.499327       0.009785  \n",
            "13       0.197742      0.000723        0.497674       0.009820  \n",
            "14       0.189078      0.000722        0.496468       0.009846  \n",
            "15       0.181619      0.000732        0.495561       0.009862  \n",
            "16       0.175224      0.000725        0.494897       0.009874  \n",
            "17       0.169720      0.000725        0.494397       0.009887  \n",
            "18       0.164996      0.000732        0.494022       0.009900  \n",
            "19       0.160951      0.000756        0.493740       0.009908  \n",
            "20       0.157470      0.000772        0.493523       0.009902  \n",
            "21       0.154493      0.000754        0.493363       0.009902  \n",
            "22       0.151922      0.000755        0.493218       0.009911  \n",
            "23       0.149744      0.000758        0.493142       0.009916  \n",
            "24       0.147860      0.000745        0.493063       0.009910  \n",
            "25       0.146257      0.000757        0.493016       0.009910  \n",
            "26       0.144861      0.000753        0.492964       0.009917  \n",
            "27       0.143671      0.000752        0.492927       0.009924  \n",
            "28       0.142652      0.000743        0.492903       0.009923  \n",
            "29       0.141782      0.000737        0.492879       0.009932  \n",
            "30       0.141046      0.000737        0.492869       0.009936  \n",
            "31       0.140412      0.000735        0.492855       0.009935  \n",
            "32       0.139869      0.000758        0.492847       0.009932  \n",
            "33       0.139401      0.000768        0.492835       0.009931  \n",
            "34       0.138996      0.000771        0.492827       0.009933  \n",
            "35       0.138660      0.000764        0.492828       0.009931  \n",
            "36       0.138371      0.000762        0.492825       0.009927  \n",
            "37       0.138121      0.000764        0.492816       0.009933  \n",
            "38       0.137903      0.000772        0.492814       0.009933  \n",
            "39       0.137729      0.000773        0.492821       0.009930  \n",
            "40       0.137560      0.000766        0.492821       0.009932  \n",
            "41       0.137419      0.000761        0.492816       0.009931  \n",
            "42       0.137298      0.000764        0.492817       0.009940  \n",
            "43       0.137185      0.000767        0.492813       0.009939  \n"
          ]
        }
      ],
      "source": [
        "# calculating metrics based on 5-fold cross-validation\n",
        "cv_results = xgb.cv(\n",
        "   params,\n",
        "   dtrain_reg,\n",
        "   num_boost_round=n,\n",
        "   nfold=5,\n",
        "   metrics = [\"mae\", \"rmse\"],\n",
        "   early_stopping_rounds=10\n",
        ")\n",
        "\n",
        "print(cv_results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating deviance explained using mean absolute loss\n",
        "train_preds = xgb_freq.predict(dtrain_reg)\n",
        "test_preds = xgb_freq.predict(dtest_reg)\n",
        "train_dev = mean_absolute_error(df_train[\"Frequency\"], train_preds)\n",
        "test_dev = mean_absolute_error(df_test[\"Frequency\"], test_preds)\n",
        "means_train = [df_train[\"Frequency\"].mean()] * len(df_train[\"Frequency\"])\n",
        "means_test = [df_test[\"Frequency\"].mean()] * len(df_test[\"Frequency\"])\n",
        "train_null = mean_absolute_error(df_train[\"Frequency\"], means_train)\n",
        "test_null = mean_absolute_error(df_test[\"Frequency\"], means_test)\n",
        "train_devex = 1 - (train_dev / train_null)\n",
        "test_devex = 1 - (test_dev / test_null)\n",
        "print(\"train-deviance-explained\", train_devex)\n",
        "print(\"test-deviance-explained\", test_devex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2j1eUB3f5tU",
        "outputId": "5f32be91-38cf-46e0-8b5a-9a821bffc860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train-deviance-explained 0.18130524368342882\n",
            "test-deviance-explained 0.15389371021455556\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}